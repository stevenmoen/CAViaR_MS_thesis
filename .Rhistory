#' @param orig - forecast origin
#' @param end - forecasting ending. Note: as the function is currently written on 2/24, this option doesn't do anything.
#' @param m - number of diffusion indices to use
#' @param tau - VaR level
#' @param mod_di - use the modified DI?
#'
#' @return - returns a list of the loss sum and the loss vector
#' @export
#'
#' @examples - loss_calc(pc_df[,1], pc_df[,-1], 757, 1027, 1, 0.01)
loss_calc = function(y, x, orig, m, tau, mod_di = 0, ar_tf = 1, p = 1, print_mdl = 0, model = 1, end = NULL){
# Extract y_hat values
if (mod_di == 0){
di = mod_di(y=y,x=x,orig=orig,m=m, tau=tau, end = end, print_mdl = print_mdl)
}
else {
di = mod_di_wl(y=y,x=x,orig=orig,m=m, tau=tau, ar_tf = ar_tf, p = p, print_mdl = print_mdl, model = model, end = end)
}
# mod_di_wl = function (y, x, orig, m, tau, ar_tf = 1, p = 1, print_mdl = 0, model = 1)
yhat = di$yhat[1:(end-orig)]
# Calculate the loss
# Initialize loss vector
lvec = rep(0,(end-orig))
# Take the difference
for (i in 1:(end-orig)){
# Calculate an indicator variable
ind = ifelse(y[orig+i] < yhat[i], 1,0)
# Use indicator in function below
lvec[i] = (tau - ind)*(y[orig+i] - yhat[i])
}
# Add up the losses - change to look at sum of losses. Won't change decision criterion
sumloss = sum(lvec)
# sumloss = sum(lvec)/length(lvec)
return(list(sumloss,lvec))
}
#' Function that selects the optimal number of predictors
#'
#' @param y - response vector
#' @param x - predictor variables
#' @param orig - forecast origin
#' @param end - ending of validation set
#' @param tau - VaR in question
#' @param low_m - low value of m to consider
#' @param high_m - high value of m to consider
#'
#' @return - returns the optimal value of m
#' @export
#'
#' @examples - opt_m(pc_df[,1], pc_df[,-1], 757, 1027, 0.01, low_m =1, high_m  = 5)
opt_m = function(y, x, orig, end = NULL, tau, low_m = 1, high_m, mod_di = 0, ar_tf = 1, p = 1, print_mdl = 0, model = 1, rowname = NULL){
# Initialize a loss vector
loss_vec = rep(0,high_m-low_m + 1)
# Initialize an m vector
m_vec = seq(low_m, high_m, by = 1)
# Loop through and populate the loss vector
for (i in 1:length(loss_vec)){
loss_vec[i] = quiet(loss_calc(y=y,x=x,orig=orig,end=end, m = m_vec[i], tau = tau, mod_di = mod_di, ar_tf = ar_tf, p = p, print_mdl = print_mdl, model = model))[[1]]
}
# Find the minimizer
opt_m = which.min(loss_vec)
opt_p = NA
# Combine into a data frame
df = as.data.frame(cbind(opt_m, opt_p))
names(df) <- c("Optimal m", "Optimal p")
# Assign a rowname
if (is.null(rowname) == TRUE){
# Write the row names
rownames(df) <- c("MV CAViaR")
}
else {
rownames(df) <- rowname
}
# Return the loss_vector and the minimzer
return(list(opt_m, loss_vec, df))
}
#' Function that selects the optimal number of lags
#'
#' @param y - response vector
#' @param x - predictor variables
#' @param orig - forecast origin
#' @param end - ending of validation set
#' @param tau - VaR in question
#' @param low_m - low value of m to consider
#' @param high_m - high value of m to consider
#'
#' @return - returns the optimal value of m
#' @export
#'
#' @examples - opt_mp(y = pc_df[,1], x = pc_df[,-1], orig = 757, end = 1007, tau = 0.01, low_m =1, high_m  = 5, low_p = 1, high_p = 10, ar_tf = 2, mod_di = 1)
opt_mp = function(y, x, orig, end = NULL, tau, low_m = 1, high_m, low_p = 1, high_p, mod_di = 0, ar_tf = 1, print_mdl = 0, model = 1, print_mp = 0, rowname = NULL){
# Initialize a loss matrix
loss_mat = matrix(0, high_p-low_p + 1,high_m-low_m + 1)
# Initialize a p vector
p_vec = seq(low_p, high_p, by = 1)
# Loop through and populate the loss vector
for (i in 1:nrow(loss_mat)){
loss_mat[i,] = opt_m(y = y, x = x, orig = orig, end = end, tau = tau, low_m = low_m, high_m  = high_m, p = i, mod_di = mod_di, ar_tf = ar_tf, print_mdl = print_mdl, model = model)[[2]]
}
# Find the minimizer
opt_p = which(loss_mat == min(loss_mat), arr.ind = TRUE)[1,1]
opt_m = which(loss_mat == min(loss_mat), arr.ind = TRUE)[1,2]
# Print the optimal p and optimal m
df = as.data.frame(cbind(opt_m, opt_p))
names(df) <- c("Optimal m", "Optimal p")
# Assign a rowname
if (is.null(rowname) == TRUE){
if (ar_tf == 1){
# Write the row names
rownames(df) <- c("MV CAViaR + AR")
} else if (ar_tf == 2){
# Write the row names
rownames(df) <- c("MV CAViaR + SAV")
} else if (ar_tf == 3){
# Write the row names
rownames(df) <- c("MV CAViaR + AS")
} else {
rownames(df) <- c("Unknown Model")
}
}
else {
rownames(df) <- rowname
}
# Print the df if the option is turned on
if (print_mp == 1){
print(df)
}
# Return the loss_vector and the minimzer
return(list(opt_m, opt_p, loss_mat, df))
}
#' A function that combines optimal values of m and p into a final table
#'
#' @param m1 - the data frame from the "MV CAViaR" run
#' @param m2 - the data frame from the "MV CAViaR + AR" run
#' @param m3 - the data frame from the "MV CAViaR + SAV" run
#' @param m4 - the data frame from the "MV CAViaR + AS" run
#'
#' @return - a nicely formatted table
#' @export
#'
#' @examples - pretty_pm(opt_pred_nl[[3]], opt_pm_m1[[4]], opt_pm_m2[[4]], opt_pm_m3[[4]])
pretty_pm = function(m1, m2, m3, m4){
# Merge the individual data frames
pm_pretty_df = rbind(m1, m2, m3, m4)
# Format nicely
pm_pretty_df %>% kable(caption = "Optimal Number of Diffusion Indices (m) and Lags (p) for Different Models", digits = 0) %>% kable_styling("striped", full_width = F) %>% kable_styling() %>% footnote(general = "The MV CAViaR model doesn't have an optimal value for p because there are no AR lags in the model"
)
}
#' Here is a function that runs the univariate CAViaR model 4 times
#'
#' @param df - the percent change data frame to consider
#' @param nfcst - number of forecasts to run
#' @param tau - the VaR level to consider
#' @param no_run - specifies if any models should not be run
#'
#' @return - a list of the 4 univariate model forecasts
#' @export
#'
#' @examples - aceg = gen_uv_test(pc_df, 1, 0.05, no_run = c(1,1,0,1))
gen_uv_test = function(df, nfcst, tau, no_run = c(0,0,0,0)){
# model type (1 - SAV, 2 - AS, 3 - GARCH, 4 - ADAPTIVE)
# Initialize a list
out_list = list()
# Run the four models - model 1; SAV
if (no_run[1] == 0){
uvcav_1 = rolling_predictions(df[,1], range_data = (1:length(df[,1])), nfcst = nfcst, model = 1, G = 10, col = 1, level = tau)
}
# Add a filler if there's no entry
else {
uvcav_1 = 0
}
# Model 2 - AS
if (no_run[2] == 0){
uvcav_2 = rolling_predictions(df[,1], range_data = (1:length(df[,1])), nfcst = nfcst, model = 2, G = 10, col = 1, level = tau)
}
else {
uvcav_2 = 0
}
# Model 3 - GARCH
if (no_run[3] == 0){
uvcav_3 = rolling_predictions(df[,1], range_data = (1:length(df[,1])), nfcst = nfcst, model = 3, G = 10, col = 1, level = tau)
}
else {
uvcav_3 = 0
}
# Model 4 - Adaptive
if (no_run[4] == 0){
uvcav_4 = rolling_predictions(df[,1], range_data = (1:length(df[,1])), nfcst = nfcst, model = 4, G = 10, col = 1, level = tau)
}
else {
uvcav_4 = 0
}
# Export the data as a list
return(list(uvcav_1, uvcav_2, uvcav_3, uvcav_4))
}
#' Function to plot the data which we generate in previous functions
#'
#' @param plot_matrix - matrix with the data to plot
#' @param norm_value - what to subtact from the data to make it on a percentage change basis. Default is 100.
#'
#' @return
#' @export - a plot of the data by diffusion index number
#'
#' @examples = plt_data(plot_mtx[[1]]), abc = plt_data(plot_mat, tau = 0.01)
plt_data = function(plot_matrix, tau, resp_var, ntest){
# Establish a maximum and minimum value
max_val = max(plot_matrix[,1:ncol(plot_matrix)])
min_val = min(plot_matrix[,1:ncol(plot_matrix)])
# Calculate inital and ending time value
start = index(plot_matrix)[1]
end = index(plot_matrix)[nrow(plot_matrix)]
ind_vals = index(plot_matrix) - start
# Create an initial plot and add lines
for (i in 1:ncol(plot_matrix)){
if (i == 1){
# 4/2/2020 - fixing the index
plot.ts(ind_vals,plot_matrix[,i], type = "l", xlab = paste("Days Since", as.Date(start)), ylab = "Approx. Percent Change in PG", ylim = c(min_val,max_val), lwd = 1, main = paste("Predicting", resp_var, "Returns from", as.Date(start), "to", as.Date(end)), sub = paste("The VaR Level is ", 100*tau, "%", "; There are ", ntest, " Trading Days Plotted Above", sep = ""))
# plot.ts(index(plot_matrix), plot_matrix[,i], type = "l", xlab = "Trading Days", ylab = "Percent Change in PG", ylim = c(min_val,max_val), lwd = 1, main = "Predicting PG Returns Over Last 250 Trading Days in 2008", sub = paste("The VaR Level is ", 100*tau, "%", sep = ""))
} else if(i %in% seq(2,8,1)) {
lines(ind_vals,plot_matrix[,i], col = i-1, lty = 2)
} else {
lines(ind_vals,plot_matrix[,i], col = i-1, lty = 2, lwd = 2)
}
}
# Define a sequence for plotting
plot_seq = seq(1, ncol(plot_matrix))
legend("topleft", legend = c(colnames(plot_matrix)), col = plot_seq, lty = c(1, rep(2, 7), rep(3, ifelse(ncol(plot_matrix)-8 <= 0, 0, ncol(plot_matrix)-8))), lwd = c(1, rep(1, 7), rep(2, ifelse(ncol(plot_matrix)-8 <= 0, 0, ncol(plot_matrix)-8))))
# Add a line for 0
# abline(h = 0, col = "black", lty = 2)
}
#' A function to calculate losses based on the test sample
#'
#' @param true_vec - the true vector of returns
#' @param pred_vec - the predicted vector from the model runs
#' @param tau - VaR level. Must match what the model used
#'
#' @return - total losses and the entire loss vector
#' @export
#'
#' @examples
loss_test = function(true_vec, pred_vec, tau){
# Initialize a loss vector
lvec = rep(0, length(true_vec))
# Initialize a break vector to see when VaR is broken
bvec = rep(0, length(true_vec))
for (i in 1:length(true_vec)){
# Calculate an indicator variable
bvec[i] = ifelse(true_vec[i] < pred_vec[i], 1,0)
# Use indicator in function below
lvec[i] = (tau - bvec[i])*(true_vec[i] - pred_vec[i])
}
# Add up the losses
# sumloss = sum(lvec)/length(lvec)
sumloss = sum(lvec)
# Add up the VaR breakage
varbreak = sum(bvec)/length(bvec)
return(list(sumloss,lvec, varbreak, bvec))
}
#' A function to calculate losses based on the plot matrix
#'
#' @param data_mat - a matrix of forecasted VaR values, with the true value in the first column
#' @param tau - VaR level. Must match what the model used
#'
#' @return - a list of four items.
#' 1 = a vector of the losses of all models.
#' 2 = a vector showing the percentage of VaR breaks by model
#' 3 = the loss matrix
#' 4 = the break matrix
#' @export
#'
#' @examples
gen_loss_test = function(data_mat, tau){
# Initialize loss and break matrices
lmat = bmat = matrix(0, nrow = nrow(data_mat), ncol = ncol(data_mat)-1)
# bvec = rep(0, length(true_vec))
# Populate the matrices
for (i in 1:nrow(lmat)){
for (j in 1:(ncol(lmat))){
# Calculate an indicator variable
bmat[i,j] = ifelse(data_mat[i,1] < data_mat[i,j+1], 1,0)
# Use indicator in function below
lmat[i,j] = (tau - bmat[i,j])*(data_mat[i,1] - data_mat[i,j+1])
}
}
# Add up the losses
sumloss = colSums(lmat)
# Add up the VaR breakage
varbreak = colSums(bmat)/nrow(bmat)
return(list(sumloss, varbreak, lmat, bmat))
}
#' A function to make a nice comparison of losses
#'
#' @param data_mat - input data matrix used in the calculation of losses
#' @param loss_list - a list of the losses calculated from the CAViaR function
#' @param tau - the risk level used
#' @param ntest - the number of test points
#'
#' @return
#' @export - returns a nicely formatted table
#'
#' @examples - pretty_tables(plot_mat, l_list, tau = 0.01)
pretty_tables = function(data_mat, loss_list, tau, ntest){
# Combine into a data frame
df = as.data.frame(rbind(loss_list[[1]], loss_list[[2]]))
# Calculate inital and ending time value
start = index(data_mat)[1]
end = index(data_mat)[nrow(data_mat)]
# Add row/column names
colnames(df) <- colnames(data_mat[,-1])
rownames(df) <- c("Losses", "VaR Breaks (%)")
# Edits on 5.12.2020 - divide the table into 2
uv_df = df[,1:4]
mv_df = df[,5:8]
# print(uv_df)
# print(mv_df)
# Convert to table
print(uv_df %>% kable(caption = paste("Univariate CAViaR Results for a ", tau*100, "% VaR", sep = ""), digits = 3) %>% kable_styling("striped", full_width = F) %>% kable_styling() %>% footnote(general = paste("Calculated using", ntest, "trading days from", as.Date(start), "to", as.Date(end))))
print(mv_df %>% kable(caption = paste("Multivariate CAViaR Results for a ", tau*100, "% VaR", sep = ""), digits = 3) %>% kable_styling("striped", full_width = F) %>% kable_styling() %>% footnote(general = paste("Calculated using", ntest, "trading days from", as.Date(start), "to", as.Date(end))))
# Convert to a table
# df %>% kable(caption = paste("Comparison of VaR Methods for a ", tau*100, "% VaR", sep = ""), digits = 3) %>% kable_styling("striped", full_width = F) %>% kable_styling() %>% footnote(general = paste("Calculated using", ntest, "trading days from", as.Date(start), "to", as.Date(end)))
# cc_df[-(1:2),] %>% kable(caption = "Accuracy of VaR Forecast for PG Over Last 200 Trading Days in 2008", digits = 3) %>% kable_styling(full_width = F) %>% footnote(general = "Tested Using the Symmetric Absolute Value Model")
}
#' A dressed up version of the export function
#'
#' @param var_file - file to export
#' @param path - filepath
#' @param filename - name of the file, ending with .CSV
#'
#' @return
#' @export - exported CSV file
#'
#' @examples - exp_func(var_file = var_1pc_2016_usetf[[1]], path = "/Users/stevenmoen/Documents/GitHub/CAViaR_MS_thesis/Data_Export/SPY_US_ETF_runs/", filename = "TEST.csv")
exp_func = function(var_file, path, filename){
# Write a zoo
write.zoo(var_file, paste0(path, filename), quote = FALSE, sep = ",")
}
# exp_func(var_file = var_1pc_2016_usetf[[1]], path = "/Users/stevenmoen/Documents/GitHub/CAViaR_MS_thesis/Data_Export/SPY_US_ETF_runs/", filename = "TEST.csv")
#' This is the "master" function where we'll evaluate the importance of the VaR model over several time periods
#'
#' @param symbol_list - a list of symbols to feed into the model
#' @param resp_var - the response variable
#' @param compl_case - should the model require complete cases? Default value is 1.
#' @param adj_close - use adjusted close price for the predictors? Default value is 1.
#' @param resp_adj_close - use adjusted close price for the response? Default value is 1.
#' @param start_date - start date to pull data from
#' @param end_date - end date to pull data from
#' @param nval - number of validation points to use
#' @param ntest - number of test points to use
#' @param tau - VaR level to use
#' @param low_m - low number of predictors to test
#' @param high_m  - low number of predictors to test
#' @param uv_list - a list of a pre-run univariate model. If a data frame is not provided, the lengthy uv model will run
#' @param no_run - things not to run in the model
#' @param low_p - low value for number of lags
#' @param high_p - high value for number of lags
#' @param na_interp - should the function interpolate NA's
#' @param print_mdl - print the model summaries?
#' @param print_mp - print the optimal values for p and m
#' @param lag_pred - do you want to lag the m predictors (default is 1; strongly recommended)
#' @param rowname - what to name the rows of the nice p and m matrix
#' @param export_csv - do you want to export a CSV? Default is 1.
#' @param path - path to export the CSV
#' @param filename - what to name the CSV
#'
#' @return - a list of the plot matrix, a plot, a list with losses, and a table
#' @export - a plot and a table
#'
#' @examples - cav_simul(c("DIS", "GE", "IBM", "MMM", "XOM"), resp_var = "PG", start_date = "2004-01-01", end_date = "2008-12-31", nval = 250, ntest = 250, low_m = 1, high_m = 5, tau = 0.01, uv_list = uv_cav_list)
cav_simul = function(symbol_list, resp_var, compl_case = 1, adj_close = 1, resp_adj_close = 1, start_date = "1900-01-01", end_date = Sys.Date(), nval, ntest, tau, low_m = 1, high_m, low_p = 1, high_p, uv_list = NULL, no_run = c(0,0,0,0), na_interp = TRUE, print_mdl = 0, print_mp = 0, lag_pred = 1, rowname = NULL, export_csv = 1, path, filename){
# Select data parameters, pull the data, and percent change the data
df = diff_index_df(symbol_list = symbol_list, resp_var = resp_var, compl_case = compl_case, adj_close = adj_close, resp_adj_close = resp_adj_close, start_date = start_date, end_date = end_date, lag_pred = lag_pred)
# Take the percent change of the data
pc_df = pc_diff_index(df)
# Extract the legnth of the data frame
nr = test_end = nrow(pc_df)
# Calculate the start of the val period, the end of the val period, and the beginning and end of test period
test_orig = test_end - ntest
val_end = test_orig
val_orig = test_orig - nval
# Test for the optimal number of parameters
opt_pred_nl = opt_m(y = pc_df[,1], x = pc_df[,-1], orig = val_orig, end = val_end, tau = tau, low_m = low_m, high_m = high_m, rowname = rowname)
opt_pred_art1 = opt_mp(y = pc_df[,1], x = pc_df[,-1], orig = val_orig, end = val_end, tau = tau, low_m = low_m, high_m = high_m, low_p = low_p, high_p = high_p,mod_di = 1, ar_tf = 1, print_mdl = print_mdl, print_mp = print_mp, rowname = rowname)
opt_pred_art2 = opt_mp(y = pc_df[,1], x = pc_df[,-1], orig = val_orig, end = val_end, tau = tau, low_m = low_m, high_m = high_m, low_p = low_p, high_p = high_p,mod_di = 1, ar_tf = 2, print_mdl = print_mdl, print_mp = print_mp, rowname = rowname)
opt_pred_art3 = opt_mp(y = pc_df[,1], x = pc_df[,-1], orig = val_orig, end = val_end, tau = tau, low_m = low_m, high_m = high_m, low_p = low_p, high_p = high_p, mod_di = 1, ar_tf = 3, print_mdl = print_mdl, print_mp = print_mp, rowname = rowname)
# gen_uv_test(pc_df, 1, 0.05, no_run = c(1,1,0,1))
# Use the above forecasts to input into the above
mv_fcst = mod_di(pc_df[,1], pc_df[,-1], orig = test_orig, m = opt_pred_nl[[1]], tau = tau, print_mdl = print_mdl)
mv_fcst_art1 = mod_di_wl(pc_df[,1], pc_df[,-1], orig = test_orig, m = opt_pred_art1[[1]], p = opt_pred_art1[[2]], tau = tau, ar_tf = 1, print_mdl = print_mdl)
mv_fcst_art2 = mod_di_wl(pc_df[,1], pc_df[,-1], orig = test_orig, m = opt_pred_art2[[1]], p = opt_pred_art2[[2]], tau = tau, ar_tf = 2, print_mdl = print_mdl)
mv_fcst_art3 = mod_di_wl(pc_df[,1], pc_df[,-1], orig = test_orig, m = opt_pred_art3[[1]], p = opt_pred_art3[[2]], tau = tau, ar_tf = 3, print_mdl = print_mdl)
# Calculate the number of predictions
if (is.null(uv_list) == TRUE){
# Print a warning
print("WARNING: Not supplying an input data frame will require this function to run for a significant amount of time (1hr+)")
# Call the function
# gen_uv_test = function(df, nfcst, tau, no_run = c(0,0,0,0)){
# print(head(pc_df))
uv_list = gen_uv_test(df = pc_df, nfcst = ntest, tau = tau, no_run = no_run)
# Add to a data frame
# Incorporate the rolling predictions function results here
plot_mat = cbind(pc_df[(test_orig+1):nrow(pc_df),1], mv_fcst$yhat[1:ntest], mv_fcst_art1$yhat[1:ntest], mv_fcst_art2$yhat[1:ntest], mv_fcst_art3$yhat[1:ntest], uv_list[[1]][(test_orig+1):test_end]*(-1), uv_list[[2]][(test_orig+1):test_end]*(-1), uv_list[[3]][(test_orig+1):test_end]*(-1), uv_list[[4]][(test_orig+1):test_end]*(-1))
} else {
# Assign the columns of the data frame
# head(var_5pc_2010_usetf[[1]][,6:9])
# model type (1 - SAV, 2 - AS, 3 - GARCH, 4 - ADAPTIVE)
# test_df = head(var_5pc_2010_usetf[[1]][,6:9])
# test_df$SAV
# test_df$`Abs. Slope`
# test_df$`Ind. GARCH`
# test_df$Adaptive
plot_mat = cbind(pc_df[(test_orig+1):nrow(pc_df),1], mv_fcst$yhat[1:ntest], mv_fcst_art1$yhat[1:ntest], mv_fcst_art2$yhat[1:ntest], mv_fcst_art3$yhat[1:ntest], uv_list$SAV, uv_list$`Abs. Slope`, uv_list$`Ind. GARCH`, uv_list$Adaptive)
}
# Count the NAs and print a warning
print(paste("NOTE: There are ", sum(is.na(plot_mat)), " NA(s) in the dataset", sep = ""))
# Linearly interpolate the NAs
if (na_interp == TRUE){
# Assign the plot matrix to a new value
plot_mat_na <- plot_mat
# Print a warning
print("WARNING: There were missing values in the plot matrix.")
# Interpolate the NA's
for (i in 1:ncol(plot_mat_na)){
# Interpolate the data
plot_mat[,i] <- na.approx(plot_mat_na[,i])
}
}
# model type (1 - SAV, 2 - AS, 3 - GARCH, 4 - ADAPTIVE)
# Add descriptive titles onto the plot_mat
colnames(plot_mat) <- c(resp_var, "MV CAViaR", "MV CAViaR + AR", "MV CAViaR + SAV", "MV CAViaR + AS", "SAV", "Abs. Slope", "Ind. GARCH", "Adaptive")
# colnames(plot_mat) <- c("SPY", "MV CAViaR", "MV CAViaR + AR", "MV CAViaR + SAV", "MV CAViaR + AS", "SAV", "Abs. Slope", "Ind. GARCH", "Adaptive")
# Plot everything
plot = plt_data(plot_mat, tau = tau, resp_var = resp_var, ntest = ntest)
# Calculate losses
l_list = gen_loss_test(plot_mat, tau = tau)
# Put into tables
tables = pretty_tables(plot_mat, l_list, tau = tau, ntest = ntest)
# Run the function for optimal p and m
pm_table = pretty_pm(opt_pred_nl[[3]], opt_pred_art1[[4]], opt_pred_art2[[4]], opt_pred_art3[[4]])
# Export the matrix
if (export_csv == 1){
exp_func(var_file = plot_mat, path, filename)
}
# Print the tables and the plot
print(plot)
print(tables)
print(pm_table)
return(list(plot_mat, plot, l_list, tables, plot_mat_na, pm_table))
}
#' A function to input the VaR files, plot them and generate tables
#'
#' @param file_path - file path to use
#' @param filename - name of the file
#' @param tau - quantile to use
#' @param resp_var - response variable to use in the plot
#' @param ntest - number of test points
#' @param cn_input - column name inputs
#'
#' @return - a list of the xts file, the plot, the loss list, and tables
#' @export - a plot and tables
#'
#' @examples - test = var_input_disp("/Users/stevenmoen/Documents/GitHub/CAViaR_MS_thesis/Data_Export/SPY_US_ETF_runs/","var_1pc_2008_us_etf.csv", 0.01)
var_input_disp = function(file_path, filename, tau, resp_var = "SPY", ntest = 250, cn_input = c("SPY", "No AR", "AR", "SAV AR", "AS AR", "SAV", "Asym. Slope", "Ind. GARCH", "Adaptive"), print_graph = 1, print_mv_table = 1, print_uv_table = 1, print_opt_param =1){
# Import data
plot_mat = read.csv(paste0(file_path,filename), sep = ",", header = T, stringsAsFactors = FALSE)
# Fix date format
plot_mat$Index = as.Date(plot_mat$Index)
# Convert to an xts
plot_mat = xts(plot_mat[,-1], order.by = plot_mat[,1])
# Fix column names
colnames(plot_mat) <- cn_input
# Plot everything
if (print_graph == 1){
plt_data(plot_mat, tau = tau, resp_var = resp_var, ntest = ntest)
}
# Calculate losses
l_list = gen_loss_test(plot_mat, tau = tau)
# Put into tables
df = as.data.frame(rbind(l_list[[1]], l_list[[2]]))
# Calculate inital and ending time value
start = index(plot_mat)[1]
end = index(plot_mat)[nrow(plot_mat)]
# Add row/column names
colnames(df) <- colnames(plot_mat[,-1])
rownames(df) <- c("Losses", "VaR Break Rate")
# Edits on 5.12.2020 - divide the table into 2
mv_df = df[,1:4]
uv_df = df[,5:8]
if (print_mv_table == 1){
print(knitr::kable(mv_df, digits = 3), format = 'pandoc')
cat("\n")
}
if (print_uv_table == 1){
print(knitr::kable(uv_df, digits = 3), format = 'pandoc')
cat("\n")
}
# Print the optimal parameters
if (print_opt_param == 1){
# Import the data frame
opt_pm = read.csv(paste0(file_path,paste0(substr(filename, 1, nchar(filename)-4),"_pm.csv")), sep = ",", header = T, stringsAsFactors = FALSE)
print(opt_pm)
# Fix the row and column names
# Format nicely
# print(opt_pm %>% kable(caption = "Optimal Number of Diffusion Indices (m) and Lags (p) for Different Models", digits = 0) %>% kable_styling("striped", full_width = F) %>% kable_styling() %>% footnote(general = "The MV CAViaR model doesn't have an optimal value for p because there are no AR lags in the model")
print(knitr::kable(opt_pm), format = 'pandoc')
#   cat("\n")
}
# Return the xts, the plot, the loss list, and the tables
return(list(plot_mat))
# return(list(plot_mat, plot, l_list, tables))
}
# Call the above function
v1_2008_alletf = var_input_disp("/Users/stevenmoen/Documents/GitHub/CAViaR_MS_thesis/Data_Export/SPY_all_ETF_runs/","var_1pc_2008_all_etf.csv", 0.01)
#' A function to input the VaR files, plot them and generate tables
